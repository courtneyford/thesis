{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kannada-MNIST CNN\n",
    "\n",
    "## 1: Train Model & Prepare Case Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 08:59:30.611803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.core.numeric import full\n",
    "import pickle\n",
    "import time\n",
    "import random \n",
    "import pprint\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, UpSampling2D, BatchNormalization, Activation, Reshape, Conv2DTranspose, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# from keras.layers import Input, Dense, Activation, Lambda, Reshape, Flatten\n",
    "# from keras.layers import BatchNormalization\n",
    "# from keras import losses\n",
    "# from keras import backend as K\n",
    "# from keras.losses import mse\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# LIME\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.segmentation import mark_boundaries, slic\n",
    "from scipy import ndimage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "# Load the data\n",
    "X_train = load('X_kannada_MNIST_train.npz')\n",
    "X_test = load('X_kannada_MNIST_test.npz')\n",
    "y_train = load('y_kannada_MNIST_train.npz')\n",
    "y_test = load('y_kannada_MNIST_test.npz')\n",
    "\n",
    "oh_y_train = to_categorical(y_train)\n",
    "oh_y_test = to_categorical(y_test)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# Output the shapes\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "#check tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 08:59:38.154760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 54s 227ms/step - loss: 0.2727 - accuracy: 0.9177 - val_loss: 0.1605 - val_accuracy: 0.9524\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 53s 226ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.1347 - val_accuracy: 0.9618\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0290 - accuracy: 0.9915\n",
      "Training Set: \n",
      "accuracy: 99.15%\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.1347 - accuracy: 0.9618\n",
      "Test Set: \n",
      "accuracy: 96.18%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Cell 1 - 28x28x1\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), padding='same', data_format='channels_last'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_last'))\n",
    "\n",
    "\n",
    "# Cell 2 - 32x4x14\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_last'))  # Removed the redundant input_shape\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_last'))\n",
    "\n",
    "# Output - 64x7x7\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation(\"softmax\"))\n",
    "\n",
    "logits = Dense(10)(model.output)  # This will give the raw logits\n",
    "\n",
    "# Applying the softmax activation separately\n",
    "predictions = Activation(\"softmax\")(logits)\n",
    "\n",
    "# Now, form the main model\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Form the logits model\n",
    "logits_model = Model(inputs=model.input, outputs=logits)\n",
    "\n",
    "model.compile(loss=CategoricalCrossentropy(),\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assuming that your data is in variables X_train, oh_y_train, X_test, oh_y_test\n",
    "model.fit(X_train, oh_y_train,\n",
    "          batch_size=256,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, oh_y_test))\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, oh_y_train)\n",
    "print(\"Training Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, oh_y_test)\n",
    "print(\"Test Set:\", \"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save(\"NN5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "knn_X_test = X_test.reshape(X_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', n_neighbors=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final k-NN \n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1, algorithm=\"brute\") \n",
    "knn_clf.fit(knn_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy Test: 0.9198\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on this particular split to make sure that it is not too far removed from k-fold.\n",
    "knn_predictions_test = knn_clf.predict(knn_X_test)\n",
    "print(\"k-NN Accuracy Test:\", accuracy_score(y_test, knn_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/courtneyford/Desktop/Computational solution/Part1_updatedtf.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/courtneyford/Desktop/Computational%20solution/Part1_updatedtf.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nn_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_classes(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/courtneyford/Desktop/Computational%20solution/Part1_updatedtf.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m right \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/courtneyford/Desktop/Computational%20solution/Part1_updatedtf.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(nn_pred)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "nn_pred = model.predict_classes(X_test)\n",
    "\n",
    "right = 0\n",
    "for i in range(len(nn_pred)):\n",
    "    if knn_predictions_test[i] == nn_pred[i]:\n",
    "        right += 1\n",
    "print(\"Agreement:\", right/len(nn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[862, 121,   2,   3,   2,   0,   0,   3,   3,   4],\n",
       "       [ 18, 971,   0,   3,   1,   0,   0,   2,   2,   3],\n",
       "       [  2,   2, 991,   1,   0,   0,   3,   0,   0,   1],\n",
       "       [ 14,  12,   2, 925,   8,   8,   2,  28,   0,   1],\n",
       "       [  0,   0,   0,   5, 974,   4,   5,   3,   2,   7],\n",
       "       [  0,  10,   7,  17, 110, 828,   3,  11,   6,   8],\n",
       "       [  2,   1,   1,   6,   8,   6, 918,  39,   1,  18],\n",
       "       [  8,   4,   1,  19,  24,   2, 105, 822,   2,  13],\n",
       "       [ 35,   5,   1,   0,   1,   0,   0,   0, 955,   3],\n",
       "       [  6,  11,   0,   0,  10,   1,   8,   4,   8, 952]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check confusion matrix kNN\n",
    "confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[936,  55,   0,   0,   2,   0,   0,   1,   5,   1],\n",
       "       [  2, 995,   0,   2,   0,   0,   0,   0,   0,   1],\n",
       "       [  2,   0, 996,   0,   0,   0,   0,   1,   0,   1],\n",
       "       [  0,   8,   1, 949,  10,  11,   6,  14,   0,   1],\n",
       "       [  0,   0,   1,   0, 991,   1,   1,   3,   1,   2],\n",
       "       [  0,   1,   1,   0,  46, 952,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   4,   1, 975,   1,   2,  16],\n",
       "       [  9,   1,   2,   8,   4,   0,  42, 928,   2,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0, 997,   2],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,   3, 996]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check confusion matrix NN \n",
    "confusion_matrix(y_test, model.predict_classes(X_test), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CBR model to disk\n",
    "pickle.dump(knn_clf, open('k-nn_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras Models to disk\n",
    "model.save(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframes\n",
    "np.save(\"X_train\", X_train)\n",
    "np.save(\"X_test\", X_test)\n",
    "np.save(\"y_train\", y_train)\n",
    "np.save(\"y_test\", y_test)\n",
    "\n",
    "np.save(\"knn_X_train\", knn_X_train)\n",
    "np.save(\"knn_X_test\", knn_X_test)\n",
    "\n",
    "np.save(\"oh_y_train\", oh_y_train)\n",
    "np.save(\"oh_y_test\", oh_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
