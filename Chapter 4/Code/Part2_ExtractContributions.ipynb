{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Extract Contributions of Latent Features & Saliency Maps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "# import deeplift\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# For Deep Learning Explanations\n",
    "# from deepexplain.tensorflow import DeepExplain\n",
    "# from deeplift.conversion import kerasapi_conversion as kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "oh_y_train = np.load(\"oh_y_train.npy\")\n",
    "oh_y_test = np.load(\"oh_y_test.npy\")\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB: MAKE SURE CORRECT MODEL\n",
    "model = load_model(\"NN2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For indexing\n",
    "nn_preds_test = model.predict(X_test)\n",
    "nn_preds_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
    "    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "\n",
    "        return activations\n",
    "\n",
    "\n",
    "X_train_act = list()\n",
    "X_test_act = list()\n",
    "\n",
    "for i in range(0, 60000, 1000):\n",
    "    #print(i)\n",
    "    start = i\n",
    "    end = i + 1000\n",
    "    \n",
    "    X_train_act_seg = get_activations(model, X_train[start: end])\n",
    "    X_train_act.append(X_train_act_seg)\n",
    "    \n",
    "    \n",
    "for i in range(0, 10000, 1000):\n",
    "    #print(i)\n",
    "    start = i\n",
    "    end = i + 1000\n",
    "    \n",
    "    X_test_act_seg = get_activations(model, X_test[start: end])\n",
    "    X_test_act.append(X_test_act_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_act_new = list()\n",
    "X_test_act_new = list()\n",
    "\n",
    "for group in X_train_act:\n",
    "    for i in range(len(group)):\n",
    "        X_train_act_new.append(group[i])\n",
    "                \n",
    "for group in X_test_act:\n",
    "    for i in range(len(group)):\n",
    "        X_test_act_new.append(group[i])        \n",
    "\n",
    "X_train_act = np.array(X_train_act_new)\n",
    "X_test_act = np.array(X_test_act_new)\n",
    "\n",
    "np.save(\"X_train_act\", X_train_act)\n",
    "np.save(\"X_test_act\", X_test_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DeepLIFT contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "deeplift_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        \"NN.h5\",\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.DeepLIFT_GenomicsDefault) \n",
    "    \n",
    "# Which layer to propagate contribution scores?\n",
    "find_scores_layer_idx = -8\n",
    "\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "                            find_scores_layer_idx=find_scores_layer_idx,\n",
    "                            target_layer_idx=-2)\n",
    "\n",
    "\n",
    "# Need to iterate scores for each output neuron one at a time (10 for MNIST)\n",
    "for i in range(model.get_weights()[-1].shape[0]):\n",
    "    \n",
    "    train = np.array(deeplift_contribs_func(task_idx=i,\n",
    "                                             input_data_list=[X_train],\n",
    "                                             batch_size=10,\n",
    "                                             progress_update=1000))\n",
    "\n",
    "    test = np.array(deeplift_contribs_func(task_idx=i,\n",
    "                                             input_data_list=[X_test],\n",
    "                                             batch_size=10,\n",
    "                                             progress_update=1000))\n",
    "    \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    train = np.expand_dims(train, 1)\n",
    "    test = np.expand_dims(test, 1)\n",
    "    \n",
    "    if i == 0:\n",
    "        X_train_deeplift = deepcopy(train)\n",
    "        X_test_deeplift = deepcopy(test)\n",
    "    else:\n",
    "        X_train_deeplift = np.append(X_train_deeplift, train, axis=1)\n",
    "        X_test_deeplift = np.append(X_test_deeplift, test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = deepcopy(X_train_deeplift)\n",
    "test = deepcopy(X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deeplift = list()\n",
    "X_test_deeplift = list()\n",
    "\n",
    "for i in range(len(nn_preds_train)):\n",
    "    index = nn_preds_train[i]\n",
    "    X_train_deeplift.append(train[i][index])\n",
    "\n",
    "for i in range(len(nn_preds_test)):\n",
    "    index = nn_preds_test[i]\n",
    "    X_test_deeplift.append(test[i][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deeplift = np.array(X_train_deeplift)\n",
    "X_test_deeplift = np.array(X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training:\", X_train_deeplift.shape)\n",
    "print(\"Testing:\", X_test_deeplift.shape)\n",
    "\n",
    "np.save(\"new_X_train_deeplift\", X_train_deeplift)\n",
    "np.save(\"new_X_test_deeplift\", X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "oh_y_train = np.load(\"oh_y_train.npy\")\n",
    "oh_y_test = np.load(\"oh_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB: MAKE SURE CORRECT MODEL\n",
    "model = load_model(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For indexing\n",
    "nn_preds_test = model.predict_classes(X_test)\n",
    "nn_preds_train = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
    "    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Contributions for Latent Features:\n",
    "Simply multiply the activations by the weights connecting to the class in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
    "    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "X_train_act_seg = get_activations(model, X_train)[-4]\n",
    "X_test_act_seg = get_activations(model, X_test)[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_act\", X_train_act_seg)\n",
    "np.save(\"X_test_act\", X_test_act_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Contribution of Features to Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preds_test = model.predict_classes(X_test)\n",
    "nn_preds_train = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe double check???\n",
    "weights = model.layers[-2].get_weights()[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cont = deepcopy(X_train_act_seg)\n",
    "X_test_cont = deepcopy(X_test_act_seg)\n",
    "\n",
    "for i in range(len(nn_preds_train)):\n",
    "    X_train_cont[i] = X_train_cont[i] * weights[nn_preds_train[i]]\n",
    "    \n",
    "for i in range(len(nn_preds_test)):\n",
    "    X_test_cont[i] = X_test_cont[i] * weights[nn_preds_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_cont\", X_train_cont)\n",
    "np.save(\"X_test_cont\", X_test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
