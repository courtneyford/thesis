{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "# For keras dependencise\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "# For LRP Visuals\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dexplain import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a value of k for the dataset\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the models from disk\n",
    "model = load_model(\"NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "# Load the feature activations\n",
    "X_train_act = np.load(\"X_train_act.npy\")\n",
    "X_test_act = np.load(\"X_test_act.npy\")\n",
    "\n",
    "# Load DeepLIFT contributions\n",
    "X_train_cont = np.load(\"new_X_train_deeplift.npy\")\n",
    "X_test_cont = np.load(\"new_X_test_deeplift.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_test_knn = X_test.reshape(X_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DeepLIFT-KNN:\", X_train_cont.shape)\n",
    "print(\"Activations:\", X_train_act.shape)\n",
    "print(\"Training:\", X_train.shape)\n",
    "print(\"Training k-NN:\", X_train_knn.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techniques = [\n",
    "    [\"k-NN*\", X_train_act, X_test_act],\n",
    "    [\"C-DeepLIFT\", X_train_cont, X_test_cont]\n",
    "             ]\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    train = item[1]\n",
    "    test = item[2]\n",
    "\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=3, algorithm=\"brute\") \n",
    "    kNN.fit(train, y_train)\n",
    "\n",
    "    knn_predictions_test = kNN.predict(test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, knn_predictions_test))\n",
    "    print(confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "    \n",
    "    # What's the % that's different?\n",
    "    correct = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if knn_predictions_test[i] == nn_pred[i]:\n",
    "            correct += 1\n",
    "    print(\"Agreement\", correct/len(nn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "X = np.load('X_train.npy')\n",
    "y = np.load('y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to sort our x data into its 10 classes\n",
    "classes = dict()\n",
    "centroids = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, 10):\n",
    "    # np.argwhere gives us the index of any item where the label is equal to the current class\n",
    "    # we're basically using the y array (which gives us the class of each corresponding x item\n",
    "    # to sort the x's into separate buckets for each label\n",
    "    classes[x] = X[np.argwhere(y == x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, ch, h, w  = 6000, 1, 28, 28\n",
    "center_points = []\n",
    "\n",
    "for class_index, cluster in classes.items():\n",
    "    center_point = np.mean(cluster, keepdims=True)\n",
    "    center_points.append(center_point)\n",
    "    distances_arr = np.array([D.euclidean(cluster_point.flatten(), center_point.flatten()) for cluster_point in cluster])\n",
    "    centroids[class_index] = cluster[np.argmin(distances_arr)]\n",
    "    \n",
    "    class_d_mean, class_d_std = distances_arr.mean(), distances_arr.std()\n",
    "    print(f\"= [{class_index}] - distance mean= {class_d_mean:0.4f} - distance std= {class_d_std:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_list = centroids.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Frequency Matrix for User Study Reserach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, idxs = kNN.kneighbors(X=[X_test_cont[5]], n_neighbors=1, return_distance=True)\n",
    "neighbour = idxs[0][0]\n",
    "explanation = y_train[neighbour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(np.array([X_test[i]]))[0] == explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[]}\n",
    "\n",
    "digits = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for digit in digits:\n",
    "\n",
    "    for i in range(len(X_test)): \n",
    "\n",
    "        if y_test[i] == digit:\n",
    "\n",
    "            # Find Neighbour label and predicted label\n",
    "            distances, idxs = kNN.kneighbors(X=[X_test_cont[i]], n_neighbors=3, return_distance=True)\n",
    "            neighbour = idxs[0][0]\n",
    "            exp_label = y_train[neighbour]\n",
    "            exp_pred = model.predict_classes(np.array([X_train[neighbour]]))[0]\n",
    "            CNN_pred = model.predict_classes(np.array([X_test[i]]))[0]\n",
    "            \n",
    "        \n",
    "            # Is systems agree\n",
    "            if CNN_pred == exp_pred:\n",
    "\n",
    "                if CNN_pred == digit and exp_label == digit:\n",
    "                    freq_dict[1].append(i) \n",
    "\n",
    "                if CNN_pred == digit and exp_label != digit:\n",
    "                    freq_dict[2].append(i)\n",
    "\n",
    "                if CNN_pred != digit and exp_label == digit:\n",
    "                    freq_dict[3].append(i)\n",
    "\n",
    "                if CNN_pred != digit and exp_label != digit:\n",
    "                    freq_dict[4].append(i)\n",
    "                    \n",
    "            # If systems disagree       \n",
    "            if CNN_pred != exp_pred:\n",
    "\n",
    "                if CNN_pred == digit and exp_label == digit:\n",
    "                    freq_dict[5].append(i) \n",
    "\n",
    "                if CNN_pred == digit and exp_label != digit:\n",
    "                    freq_dict[6].append(i)\n",
    "\n",
    "                if CNN_pred != digit and exp_label == digit:\n",
    "                    freq_dict[7].append(i)\n",
    "\n",
    "                if CNN_pred != digit and exp_label != digit:\n",
    "                    freq_dict[8].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in freq_dict.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Wrong Situations for User Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {1:[], 2:[]}\n",
    "\n",
    "digits = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for digit in digits:\n",
    "\n",
    "    for i in range(len(X_test)): \n",
    "\n",
    "        # Not terribly efficient code, but it'll do here\n",
    "        if y_test[i] == digit:\n",
    "\n",
    "            # Find Neighbour label and predicted label\n",
    "            neighbour_idxs = kNN.kneighbors(X=[X_test_cont[i]], n_neighbors=3, return_distance=False)\n",
    "            \n",
    "            neighbour_idxs = neighbour_idxs[0]\n",
    "            neighbour_labels = deepcopy(neighbour_idxs)\n",
    "            neighbour_preds = deepcopy(neighbour_idxs)\n",
    "            \n",
    "            for j in range(len(neighbour_idxs)):\n",
    "                neighbour_labels[j] = y_train[neighbour_idxs[j]]\n",
    "                neighbour_preds[j] = model.predict_classes(np.array([X_train[neighbour_idxs[j]]]))[0]\n",
    "            \n",
    "            CNN_pred = model.predict_classes(np.array([X_test[i]]))[0]\n",
    "            query_label = y_test[i]\n",
    "            \n",
    "        \n",
    "            # Situation 1\n",
    "            if CNN_pred != query_label:\n",
    "                if len(Counter(neighbour_labels)) == 1 and len(Counter(neighbour_preds)) == 1:\n",
    "                    if neighbour_labels[0] == neighbour_preds[0]:\n",
    "                        if neighbour_labels[0] == CNN_pred:\n",
    "                            freq_dict[1].append(i)\n",
    "                    \n",
    "            # Situation 2       \n",
    "            if CNN_pred != query_label:\n",
    "                if len(Counter(neighbour_labels)) == 2:\n",
    "                    if Counter(neighbour_labels).most_common()[0][0] == CNN_pred:\n",
    "                        freq_dict[2].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Most NB Feature for Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "\n",
    "# Do simplist thing possible and just log the argmax of each instance\n",
    "for i in range(len(X_train_cont)):\n",
    "    idx = np.argmax(X_train_cont[i])\n",
    "    nb_features[y_train[i]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(nb_features[9], bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(nb_features[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Explanation with White Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3, algorithm=\"brute\") \n",
    "kNN.fit(X_train_cont, y_train)\n",
    "knn_predictions_test = kNN.predict(X_test_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, knn_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(X_test)):\n",
    "#     if y_test[i] != model.predict_classes(np.array([X_test[i]])):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull list of errors to examine\n",
    "\n",
    "freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = 1075\n",
    "\n",
    "\n",
    "# Find Neighbours\n",
    "idxs = kNN.kneighbors(X=[X_test_cont[test_instance]], n_neighbors=3, return_distance=False)\n",
    "neighbours = idxs[0]\n",
    "\n",
    "\n",
    "print(\"Query Label:\", y_test[test_instance])\n",
    "print(\"Prediction:\", model.predict_classes(np.array([X_test[test_instance]]))[0])\n",
    "print(\" \")\n",
    "print(\"Neighbors:\")\n",
    "for i in range(len(neighbours)):\n",
    "    print(y_train[neighbours[i]])\n",
    "\n",
    "f, axarr = plt.subplots(1,4)\n",
    "\n",
    "axarr[0].imshow(np.squeeze(X_test[test_instance]))\n",
    "axarr[0].axis('off')\n",
    "\n",
    "axarr[1].imshow(np.squeeze(X_train[neighbours[0]]))\n",
    "axarr[1].axis('off')\n",
    "\n",
    "axarr[2].imshow(np.squeeze(X_train[neighbours[1]]))\n",
    "axarr[2].axis('off')\n",
    "\n",
    "axarr[3].imshow(np.squeeze(X_train[neighbours[2]]))\n",
    "axarr[3].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test instance centroid\n",
    "test_inst_centroid = centroids[digit][0]\n",
    "#neighbour centroid\n",
    "neighbour_centroid = centroids[digit][0]\n",
    "#difference between test instance and neighbour centroid\n",
    "diff = test_inst_centroid - neighbour_centroid\n",
    "#difference between test instance and test instance centroid\n",
    "diff_centroid = test_inst_centroid - test_inst_centroid\n",
    "\n",
    "# visualise test instance centroid\n",
    "axarr[0].scatter(test_inst_centroid[0], test_inst_centroid[1], c='r', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SSIM of test instance and neighbors to centroid\n",
    "ssim_test = []\n",
    "print(y_test[test_instance])\n",
    "ssim_neighbours = []\n",
    "for i in range(len(neighbours)):\n",
    "    ssim_test.append(ssim(np.squeeze(X_test[test_instance]), np.squeeze(X_train[neighbours[i]])))\n",
    "    ssim_neighbours.append(ssim(np.squeeze(X_test[test_instance]), np.squeeze(X_train[neighbours[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure as measure\n",
    "\n",
    "# MSE function\n",
    "\n",
    "def mse(imageA, imageB):\n",
    "    print(imageA.shape, imageB.shape)\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageB.shape[1])\n",
    "    return err\n",
    "\n",
    "# SSIM function\n",
    "def compare_image(imageA, imageA_labels, centroid):\n",
    "    imageB = centroid[imageA_labels]\n",
    "    m= mse(imageA, imageB)\n",
    "    s = measure.compare_ssim(imageA, imageB[0])\n",
    "#     s= ssim(imageA, imageB[0])\n",
    "    \n",
    "    print('ssim: ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = 1000\n",
    "\n",
    "\n",
    "# Find Neighbours\n",
    "idxs = kNN.kneighbors(X=[X_test_cont[test_instance]], n_neighbors=3, return_distance=False)\n",
    "neighbours = idxs[0]\n",
    "\n",
    "print(\"Query Label:\", y_test[test_instance])\n",
    "print(\"Prediction:\", model.predict_classes(np.array([X_test[test_instance]]))[0])\n",
    "print(\" \")\n",
    "print(\"Neighbors:\")\n",
    "for i in range(len(neighbours)):\n",
    "    print(y_train[neighbours[i]])\n",
    "\n",
    "f, axarr = plt.subplots(1,4)\n",
    "\n",
    "axarr[0].imshow(np.squeeze(X_test[test_instance]))\n",
    "axarr[0].axis('off')\n",
    "\n",
    "axarr[1].imshow(np.squeeze(X_train[neighbours[0]]))\n",
    "axarr[1].axis('off')\n",
    "axarr[2].imshow(np.squeeze(X_train[neighbours[1]]))\n",
    "axarr[2].axis('off')\n",
    "axarr[3].imshow(np.squeeze(X_train[neighbours[2]]))\n",
    "axarr[3].axis('off')\n",
    "\n",
    "\n",
    "test_inst = X_test[test_instance]\n",
    "test_inst_centroid = centroids[digit][0]\n",
    "NNdigit0 = y_train[neighbours[0]]\n",
    "NNdigit0_centroid = centroids[digit][0]\n",
    "NNdigit1 = y_train[neighbours[1]]\n",
    "NNdigit1_centroid = centroids[digit][1]\n",
    "NNdigit2 = y_train[neighbours[2]]\n",
    "NNdigit2_centroid = centroids[digit][2]\n",
    "\n",
    "\n",
    "mse_test = mean_squared_error(test_inst, test_inst_centroid)\n",
    "ssim_test = ssim(test_inst, test_inst_centroid)\n",
    "mse_compare0 = mean_squared_error(NNdigit0, NNdigit0_centroid)\n",
    "ssim_compare0 = ssim(NNdigit0, NNdigit0_centroid)\n",
    "mse_compare1 = mean_squared_error(NNdigit1, NNdigit1_centroid)\n",
    "ssim_compare1 = ssim(NNdigit1, NNdigit1_centroid)\n",
    "mse_compare2 = mean_squared_error(NNdigit2, NNdigit2_centroid)\n",
    "ssim_compare2 = ssim(NNdigit2, NNdigit2_centroid)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1,4, figsize=(10, 4),\n",
    "                         sharex=True, sharey=True)\n",
    "                         \n",
    "ax[0].imshow(np.squeeze(X_test[test_instance]))\n",
    "ax[0].set_title('Test Instance')\n",
    "ax[0].set_xlabel(f'MSE: {mse_test:.4f}, SSIM: {ssim_test:.4f}')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(np.squeeze(X_train[neighbours[0]]))\n",
    "ax[1].set_title('NN 1')\n",
    "ax[1].set_xlabel(f'MSE: {mse_compare0:.4f}, SSIM: {ssim_compare0:.4f}')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(np.squeeze(X_train[neighbours[1]]))\n",
    "ax[2].set_title('NN 2')\n",
    "ax[2].set_xlabel(f'MSE: {mse_compare1:.4f}, SSIM: {ssim_compare1:.4f}')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(np.squeeze(X_train[neighbours[2]]))\n",
    "ax[3].set_title('NN 3')\n",
    "ax[3].set_xlabel(f'MSE: {mse_compare2:.4f}, SSIM: {ssim_compare2:.4f}')\n",
    "ax[3].axis('off')\n",
    "\n",
    "\n",
    "#plt.savefig(\"Materials/Errors/KMNIST E 24.pdf\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import metrics\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "test_instance = 1693\n",
    "\n",
    "\"\"\"\n",
    "To use SSIM (or in any case general similarity function) to train the KNN algo, create a function that takes 2 inputs and\n",
    "retruns the similarity index that you aim for.\n",
    "\n",
    "Pass this function to sklearn's KNN fit method, so that distnacce \"metric\" will be the function you wrote.\n",
    "\"\"\"\n",
    "\n",
    "idxs = kNN.kneighbors(X=[X_test_cont[test_instance]], n_neighbors=3, return_distance=False)\n",
    "neighbours = idxs[0]\n",
    "\n",
    "test_image = X_test[test_instance]\n",
    "test_cont = X_test_cont[test_instance]\n",
    "image_label = y_test[test_instance]\n",
    "test_image_label = y_test[test_instance]\n",
    "\n",
    "neighbour_images = X_train_cont[neighbours]\n",
    "neighbour_labels = y_train[neighbours]\n",
    "\n",
    "\n",
    "dist = compare_image(test_image, image_label, centroids)\n",
    "print('distance test instance {} to own centroid {} : {}'.format(0, 0, dist))\n",
    "\n",
    "dist = compare_image(test_image, image_label, neighbor_images[0])\n",
    "\n",
    "neighbour_label, neighbour_image = neighbour_labels[0], neighbour_images[0],\n",
    "dist = compare_image(neighbour_image, neighbour_label, centroids)\n",
    "print('distance neighbour instance {} to neighbour centroid {} : {}'.format(0, 0, dist))\n",
    "neighbour_label, neighbour_image = neighbour_labels[1], neighbour_images[1],\n",
    "dist = compare_image(neighbour_image, neighbour_label, centroids)\n",
    "print('distance neighbour instance {} to neighbour centroid {} : {}'.format(1, 1, dist))\n",
    "neighbour_label, neighbour_image = neighbour_labels[2], neighbour_images[2],\n",
    "dist = compare_image(neighbour_image, neighbour_label, centroids)\n",
    "print('distance neighbour instance {} to neighbour centroid {} : {}'.format(2, 2, dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "78bbc0d16efdffc8e1414c00ee53b9ebf4ac9a9f212d78822034f303f56b786d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
